{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using below two technique\n",
    "1. VADER (Valence Aware Dictionary and sEntiment Reasoner) - Bag of words approach\n",
    "2. Roberta Pretrained Model from ðŸ¤— (from Huggingface Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta, datetime\n",
    "import nltk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('ggplot')\n",
    "plt.style.use('default')\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.read_csv('./data_after_processing/reviews_related_data/comments_with_keyphrases.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546736, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. VADER Seniment Scoring\n",
    "We will use NLTK's SentimentIntensityAnalyzer to get the neg/neu/pos scores of the text.\n",
    "\n",
    "This uses a \"bag of words\" approach:\n",
    "Stop words are removed\n",
    "each word is scored and combined to a total score.\n",
    "\n",
    "Important - This method does not account for the relationship between words, which in human speech is very important, but would give general idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.318, 'pos': 0.682, 'compound': 0.6468}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some examples -- compound score goes from -1 to +1\n",
    "sia.polarity_scores(\"I am so happy!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.468, 'neu': 0.532, 'pos': 0.0, 'compound': -0.6588}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(\"This is the worst day ever!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pre-trained roberta-model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply this model on all the comments data in reviews\n",
    "def polarity_scores_roberta(text):\n",
    "    encoded_txt = tokenizer(text, return_tensors='pt')\n",
    "    try:\n",
    "        output = model(**encoded_txt)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        scores_dict = {\n",
    "            'roberta_neg' : scores[0],\n",
    "            'roberta_neu' : scores[1],\n",
    "            'roberta_pos' : scores[2]\n",
    "        }\n",
    "    except:\n",
    "        scores_dict = {}\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i, row in df_comments.iterrows():      \n",
    "    try:\n",
    "        text = row['clean_comments']\n",
    "        # Applying vader --> will be useful, when roberta does not work on some comments\n",
    "        vader_result = sia.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        # Applying roberta\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {'comment': text, **vader_result_rename, **roberta_result}\n",
    "        res[i] = both\n",
    "    except RuntimeError as ex:\n",
    "        print(ex)\n",
    "        print(f'Broke for id {i}')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        print(i)\n",
    "\n",
    "pd.DataFrame(res).T.to_csv('./data_after_processing/reviews_related_data/comments_with_sentiments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the vader and roberta sentiments scores to the data which contains reviews file other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546736, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making sure the number of rows are same before joining\n",
    "df_comments_sentiments = pd.read_csv('./data_after_processing/reviews_related_data/comments_with_sentiments.csv')\n",
    "df_comments_sentiments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default join happens on indexes\n",
    "df_comments_wsent = df_comments.join(df_comments_sentiments, how='left')[[\n",
    "    'listing_id',\n",
    "    'id',\n",
    "    'date',\n",
    "    'reviewer_id',\n",
    "    'reviewer_name',\n",
    "    'comments',\n",
    "    'clean_comments',\n",
    "    'keyphrases',\n",
    "    'vader_neg',\n",
    "    'vader_neu',\n",
    "    'vader_pos',\n",
    "    'vader_compound',\n",
    "    'roberta_neg',\n",
    "    'roberta_pos',\n",
    "    'roberta_neu'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final file which will have sentiments on the clean comments\n",
    "df_comments_wsent.to_csv('./data_after_processing/reviews_related_data/comments_with_sentiments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Roberta scores from the earlier execute files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earlier executed file\n",
    "df_earlier_sentiment = pd.read_csv('./data_after_processing/comments_with_sentiments_earlier.csv')\n",
    "df_latest_sentiment = pd.read_csv('./data_after_processing/reviews_related_data/comments_with_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(546736, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latest_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>roberta_neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298820</th>\n",
       "      <td>4.420834e+07</td>\n",
       "      <td>6.680000e+17</td>\n",
       "      <td>7/10/2022</td>\n",
       "      <td>341534968</td>\n",
       "      <td>Tara</td>\n",
       "      <td>This is such a fun and unique hotel. I stayed ...</td>\n",
       "      <td>thi be such a fun and unique hotel i stay in a...</td>\n",
       "      <td>[[\"unique hotel\", 0.6277], [\"hotel\", 0.6169], ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.237</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.969624</td>\n",
       "      <td>0.028207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298821</th>\n",
       "      <td>4.420834e+07</td>\n",
       "      <td>6.680000e+17</td>\n",
       "      <td>7/10/2022</td>\n",
       "      <td>341534968</td>\n",
       "      <td>Tara</td>\n",
       "      <td>This Airbnb really makes you feel more like a ...</td>\n",
       "      <td>thi airbnb really make you feel more like a lo...</td>\n",
       "      <td>[[\"airbnb really\", 0.7086], [\"thi airbnb\", 0.6...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.957361</td>\n",
       "      <td>0.040440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330369</th>\n",
       "      <td>6.090000e+17</td>\n",
       "      <td>7.060000e+17</td>\n",
       "      <td>9/1/2022</td>\n",
       "      <td>179330149</td>\n",
       "      <td>Tiffanie</td>\n",
       "      <td>Clean, modern look. Comfortable. Easy check in...</td>\n",
       "      <td>clean modern look comfortable easy check in an...</td>\n",
       "      <td>[[\"clean modern\", 0.4293], [\"downtown area\", 0...</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>0.038508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330370</th>\n",
       "      <td>6.090000e+17</td>\n",
       "      <td>7.060000e+17</td>\n",
       "      <td>9/1/2022</td>\n",
       "      <td>179330149</td>\n",
       "      <td>Tiffanie</td>\n",
       "      <td>Great place.</td>\n",
       "      <td>great place</td>\n",
       "      <td>[[\"great place\", 1.0], [\"place\", 0.6453], [\"gr...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.932469</td>\n",
       "      <td>0.060825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337636</th>\n",
       "      <td>6.340000e+17</td>\n",
       "      <td>6.370000e+17</td>\n",
       "      <td>5/28/2022</td>\n",
       "      <td>37630698</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>We loved our stay here and highly recommend it...</td>\n",
       "      <td>we love our stay here and highly recommend it ...</td>\n",
       "      <td>[[\"decor beautiful\", 0.4506], [\"condo\", 0.4118...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.291</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.992267</td>\n",
       "      <td>0.005887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337967</th>\n",
       "      <td>6.340000e+17</td>\n",
       "      <td>6.370000e+17</td>\n",
       "      <td>5/28/2022</td>\n",
       "      <td>37630698</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>This place is stunning. We were amazed at the ...</td>\n",
       "      <td>thi place be stun we be amaze at the design an...</td>\n",
       "      <td>[[\"downtown\", 0.5692], [\"downtown highly\", 0.5...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.974107</td>\n",
       "      <td>0.024413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337968</th>\n",
       "      <td>6.340000e+17</td>\n",
       "      <td>6.400000e+17</td>\n",
       "      <td>6/1/2022</td>\n",
       "      <td>333353279</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Absolutely AMAZING stay for our bachelorette w...</td>\n",
       "      <td>absolutely amaze stay for our bachelorette wee...</td>\n",
       "      <td>[[\"bachelorette weekend\", 0.5126], [\"stay bach...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.990881</td>\n",
       "      <td>0.007674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337969</th>\n",
       "      <td>6.340000e+17</td>\n",
       "      <td>6.410000e+17</td>\n",
       "      <td>6/3/2022</td>\n",
       "      <td>62461671</td>\n",
       "      <td>Tim</td>\n",
       "      <td>We had such a great time here. Check in proces...</td>\n",
       "      <td>we have such a great time here check in proces...</td>\n",
       "      <td>[[\"visit nashville\", 0.6359], [\"nashville\", 0....</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.987834</td>\n",
       "      <td>0.010719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338026</th>\n",
       "      <td>6.340000e+17</td>\n",
       "      <td>6.400000e+17</td>\n",
       "      <td>6/1/2022</td>\n",
       "      <td>333353279</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Joes Place is spectacular! This place is exact...</td>\n",
       "      <td>joe place be spectacular thi place be exactly ...</td>\n",
       "      <td>[[\"view nashville\", 0.5825], [\"nashville skyli...</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.971101</td>\n",
       "      <td>0.026160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338027</th>\n",
       "      <td>6.340000e+17</td>\n",
       "      <td>6.410000e+17</td>\n",
       "      <td>6/3/2022</td>\n",
       "      <td>62461671</td>\n",
       "      <td>Tim</td>\n",
       "      <td>Loved the design of this place - everything wa...</td>\n",
       "      <td>love the design of thi place everythe be high ...</td>\n",
       "      <td>[[\"rooftop area\", 0.532], [\"perfect location\",...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.254</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.001430</td>\n",
       "      <td>0.986561</td>\n",
       "      <td>0.012008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          listing_id            id       date  reviewer_id reviewer_name  \\\n",
       "298820  4.420834e+07  6.680000e+17  7/10/2022    341534968          Tara   \n",
       "298821  4.420834e+07  6.680000e+17  7/10/2022    341534968          Tara   \n",
       "330369  6.090000e+17  7.060000e+17   9/1/2022    179330149      Tiffanie   \n",
       "330370  6.090000e+17  7.060000e+17   9/1/2022    179330149      Tiffanie   \n",
       "337636  6.340000e+17  6.370000e+17  5/28/2022     37630698        Ashley   \n",
       "337967  6.340000e+17  6.370000e+17  5/28/2022     37630698        Ashley   \n",
       "337968  6.340000e+17  6.400000e+17   6/1/2022    333353279         Sarah   \n",
       "337969  6.340000e+17  6.410000e+17   6/3/2022     62461671           Tim   \n",
       "338026  6.340000e+17  6.400000e+17   6/1/2022    333353279         Sarah   \n",
       "338027  6.340000e+17  6.410000e+17   6/3/2022     62461671           Tim   \n",
       "\n",
       "                                                 comments  \\\n",
       "298820  This is such a fun and unique hotel. I stayed ...   \n",
       "298821  This Airbnb really makes you feel more like a ...   \n",
       "330369  Clean, modern look. Comfortable. Easy check in...   \n",
       "330370                                       Great place.   \n",
       "337636  We loved our stay here and highly recommend it...   \n",
       "337967  This place is stunning. We were amazed at the ...   \n",
       "337968  Absolutely AMAZING stay for our bachelorette w...   \n",
       "337969  We had such a great time here. Check in proces...   \n",
       "338026  Joes Place is spectacular! This place is exact...   \n",
       "338027  Loved the design of this place - everything wa...   \n",
       "\n",
       "                                           clean_comments  \\\n",
       "298820  thi be such a fun and unique hotel i stay in a...   \n",
       "298821  thi airbnb really make you feel more like a lo...   \n",
       "330369  clean modern look comfortable easy check in an...   \n",
       "330370                                        great place   \n",
       "337636  we love our stay here and highly recommend it ...   \n",
       "337967  thi place be stun we be amaze at the design an...   \n",
       "337968  absolutely amaze stay for our bachelorette wee...   \n",
       "337969  we have such a great time here check in proces...   \n",
       "338026  joe place be spectacular thi place be exactly ...   \n",
       "338027  love the design of thi place everythe be high ...   \n",
       "\n",
       "                                               keyphrases  vader_neg  \\\n",
       "298820  [[\"unique hotel\", 0.6277], [\"hotel\", 0.6169], ...      0.000   \n",
       "298821  [[\"airbnb really\", 0.7086], [\"thi airbnb\", 0.6...      0.000   \n",
       "330369  [[\"clean modern\", 0.4293], [\"downtown area\", 0...      0.022   \n",
       "330370  [[\"great place\", 1.0], [\"place\", 0.6453], [\"gr...      0.000   \n",
       "337636  [[\"decor beautiful\", 0.4506], [\"condo\", 0.4118...      0.000   \n",
       "337967  [[\"downtown\", 0.5692], [\"downtown highly\", 0.5...      0.000   \n",
       "337968  [[\"bachelorette weekend\", 0.5126], [\"stay bach...      0.000   \n",
       "337969  [[\"visit nashville\", 0.6359], [\"nashville\", 0....      0.000   \n",
       "338026  [[\"view nashville\", 0.5825], [\"nashville skyli...      0.030   \n",
       "338027  [[\"rooftop area\", 0.532], [\"perfect location\",...      0.000   \n",
       "\n",
       "        vader_neu  vader_pos  vader_compound  roberta_neg  roberta_pos  \\\n",
       "298820      0.763      0.237          0.8979     0.002169     0.969624   \n",
       "298821      0.792      0.208          0.6990     0.002199     0.957361   \n",
       "330369      0.692      0.286          0.9531     0.002766     0.958726   \n",
       "330370      0.196      0.804          0.6249     0.006706     0.932469   \n",
       "337636      0.709      0.291          0.9633     0.001846     0.992267   \n",
       "337967      0.773      0.227          0.9738     0.001480     0.974107   \n",
       "337968      0.726      0.274          0.9703     0.001445     0.990881   \n",
       "337969      0.652      0.348          0.9949     0.001447     0.987834   \n",
       "338026      0.706      0.264          0.9855     0.002739     0.971101   \n",
       "338027      0.746      0.254          0.9712     0.001430     0.986561   \n",
       "\n",
       "        roberta_neu  \n",
       "298820     0.028207  \n",
       "298821     0.040440  \n",
       "330369     0.038508  \n",
       "330370     0.060825  \n",
       "337636     0.005887  \n",
       "337967     0.024413  \n",
       "337968     0.007674  \n",
       "337969     0.010719  \n",
       "338026     0.026160  \n",
       "338027     0.012008  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latest_sentiment[df_latest_sentiment.duplicated(subset = ['listing_id','date','id','reviewer_id'], keep = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 547928 entries, 0 to 547927\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   listing_id      547928 non-null  float64\n",
      " 1   id              547928 non-null  float64\n",
      " 2   date            547928 non-null  object \n",
      " 3   reviewer_id     547928 non-null  int64  \n",
      " 4   reviewer_name   547927 non-null  object \n",
      " 5   comments        547928 non-null  object \n",
      " 6   clean_comments  547928 non-null  object \n",
      " 7   vader_neg       546921 non-null  float64\n",
      " 8   vader_neu       546921 non-null  float64\n",
      " 9   vader_pos       546921 non-null  float64\n",
      " 10  vader_compound  546921 non-null  float64\n",
      " 11  roberta_neg     546657 non-null  float64\n",
      " 12  roberta_pos     546657 non-null  float64\n",
      " 13  roberta_neu     546657 non-null  float64\n",
      "dtypes: float64(9), int64(1), object(4)\n",
      "memory usage: 58.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_earlier_sentiment.drop(columns = ['Unnamed: 0'], inplace=True)\n",
    "df_earlier_sentiment[['listing_id', 'id']] = df_earlier_sentiment[['listing_id', 'id']].astype('float')\n",
    "df_earlier_sentiment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latest_sentiment[df_latest_sentiment['roberta_neg'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 14)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_earlier_sentiment[df_earlier_sentiment['roberta_neg'].isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249, 26)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the set difference to identify records which have the roberta values in the first execution\n",
    "df_merge_new = df_latest_sentiment[df_latest_sentiment['roberta_neg'].isna()].merge(df_earlier_sentiment, how = 'left', \n",
    "                                                                                    on = ['listing_id','id','reviewer_id'])\n",
    "df_merge_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listing_id', 'id', 'date', 'reviewer_id', 'reviewer_name', 'comments',\n",
       "       'clean_comments', 'keyphrases', 'vader_neg_x', 'vader_neu_x',\n",
       "       'vader_pos_x', 'vader_compound_x', 'roberta_neg_x', 'roberta_pos_x',\n",
       "       'roberta_neu_x', 'roberta_neg_y', 'roberta_pos_y', 'roberta_neu_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_new.drop(columns = ['date_y','reviewer_name_y','comments_y','clean_comments_y','vader_neg_y','vader_neu_y','vader_pos_y','vader_compound_y'],inplace=True)\n",
    "df_merge_new.rename(columns = {'date_x' : 'date' , 'reviewer_name_x':'reviewer_name','comments_x' : 'comments', 'clean_comments_x' : 'clean_comments'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>vader_neg_x</th>\n",
       "      <th>vader_neu_x</th>\n",
       "      <th>vader_pos_x</th>\n",
       "      <th>vader_compound_x</th>\n",
       "      <th>roberta_neg_x</th>\n",
       "      <th>roberta_pos_x</th>\n",
       "      <th>roberta_neu_x</th>\n",
       "      <th>roberta_neg_y</th>\n",
       "      <th>roberta_pos_y</th>\n",
       "      <th>roberta_neu_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17669492.0</td>\n",
       "      <td>485400987.0</td>\n",
       "      <td>7/10/2019</td>\n",
       "      <td>234139964</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Seth was a very communicative host and overall...</td>\n",
       "      <td>seth be a very communicative host and overall ...</td>\n",
       "      <td>[[\"place cleaner\", 0.4353], [\"stay house\", 0.3...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.976501</td>\n",
       "      <td>0.021514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16827497.0</td>\n",
       "      <td>352682042.0</td>\n",
       "      <td>11/25/2018</td>\n",
       "      <td>33913805</td>\n",
       "      <td>Rebekah</td>\n",
       "      <td>My husband and I thoroughly enjoyed staying at...</td>\n",
       "      <td>my husband and i thoroughly enjoy stay at ambe...</td>\n",
       "      <td>[[\"recommend bath\", 0.5464], [\"amber place\", 0...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.989222</td>\n",
       "      <td>0.009276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id           id        date  reviewer_id reviewer_name  \\\n",
       "0  17669492.0  485400987.0   7/10/2019    234139964         Sarah   \n",
       "1  16827497.0  352682042.0  11/25/2018     33913805       Rebekah   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Seth was a very communicative host and overall...   \n",
       "1  My husband and I thoroughly enjoyed staying at...   \n",
       "\n",
       "                                      clean_comments  \\\n",
       "0  seth be a very communicative host and overall ...   \n",
       "1  my husband and i thoroughly enjoy stay at ambe...   \n",
       "\n",
       "                                          keyphrases  vader_neg_x  \\\n",
       "0  [[\"place cleaner\", 0.4353], [\"stay house\", 0.3...        0.049   \n",
       "1  [[\"recommend bath\", 0.5464], [\"amber place\", 0...        0.010   \n",
       "\n",
       "   vader_neu_x  vader_pos_x  vader_compound_x  roberta_neg_x  roberta_pos_x  \\\n",
       "0        0.814        0.137            0.9938            NaN            NaN   \n",
       "1        0.779        0.211            0.9991            NaN            NaN   \n",
       "\n",
       "   roberta_neu_x  roberta_neg_y  roberta_pos_y  roberta_neu_y  \n",
       "0            NaN       0.001985       0.976501       0.021514  \n",
       "1            NaN       0.001502       0.989222       0.009276  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the roberta_y values into roberta_x and the one's which do have the roberta_y values also copy the vader score\n",
    "\n",
    "def fill_values_neg(row): \n",
    "    if np.isnan(row['roberta_neg_y']):\n",
    "       return row['vader_neg_x']\n",
    "    else:\n",
    "        return row['roberta_neg_y']    \n",
    "   \n",
    "df_merge_new['roberta_neg_x'] = df_merge_new.apply(fill_values_neg, axis = 1)\n",
    "\n",
    "def fill_values_pos(row): \n",
    "    if np.isnan(row['roberta_pos_y']):\n",
    "       return row['vader_pos_x']\n",
    "    else:\n",
    "        return row['roberta_pos_y']    \n",
    "   \n",
    "df_merge_new['roberta_pos_x'] = df_merge_new.apply(fill_values_pos, axis = 1)\n",
    "\n",
    "def fill_values_neu(row): \n",
    "    if np.isnan(row['roberta_neu_y']):\n",
    "       return row['vader_neu_x']\n",
    "    else:\n",
    "        return row['roberta_neu_y']    \n",
    "   \n",
    "df_merge_new['roberta_neu_x'] = df_merge_new.apply(fill_values_neu, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>roberta_neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17669492.0</td>\n",
       "      <td>485400987.0</td>\n",
       "      <td>7/10/2019</td>\n",
       "      <td>234139964</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>Seth was a very communicative host and overall...</td>\n",
       "      <td>seth be a very communicative host and overall ...</td>\n",
       "      <td>[[\"place cleaner\", 0.4353], [\"stay house\", 0.3...</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.9938</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.976501</td>\n",
       "      <td>0.021514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16827497.0</td>\n",
       "      <td>352682042.0</td>\n",
       "      <td>11/25/2018</td>\n",
       "      <td>33913805</td>\n",
       "      <td>Rebekah</td>\n",
       "      <td>My husband and I thoroughly enjoyed staying at...</td>\n",
       "      <td>my husband and i thoroughly enjoy stay at ambe...</td>\n",
       "      <td>[[\"recommend bath\", 0.5464], [\"amber place\", 0...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.989222</td>\n",
       "      <td>0.009276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id           id        date  reviewer_id reviewer_name  \\\n",
       "0  17669492.0  485400987.0   7/10/2019    234139964         Sarah   \n",
       "1  16827497.0  352682042.0  11/25/2018     33913805       Rebekah   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Seth was a very communicative host and overall...   \n",
       "1  My husband and I thoroughly enjoyed staying at...   \n",
       "\n",
       "                                      clean_comments  \\\n",
       "0  seth be a very communicative host and overall ...   \n",
       "1  my husband and i thoroughly enjoy stay at ambe...   \n",
       "\n",
       "                                          keyphrases  vader_neg  vader_neu  \\\n",
       "0  [[\"place cleaner\", 0.4353], [\"stay house\", 0.3...      0.049      0.814   \n",
       "1  [[\"recommend bath\", 0.5464], [\"amber place\", 0...      0.010      0.779   \n",
       "\n",
       "   vader_pos  vader_compound  roberta_neg  roberta_pos  roberta_neu  \n",
       "0      0.137          0.9938     0.001985     0.976501     0.021514  \n",
       "1      0.211          0.9991     0.001502     0.989222     0.009276  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge_new1 = df_merge_new[['listing_id','id','date','reviewer_id',\n",
    "                                'reviewer_name','comments','clean_comments','keyphrases','vader_neg_x',\n",
    "                                'vader_neu_x', 'vader_pos_x','vader_compound_x','roberta_neg_x','roberta_pos_x','roberta_neu_x']].\\\n",
    "                                    rename(columns={'vader_neg_x' : 'vader_neg', 'vader_neu_x' : 'vader_neu', 'vader_pos_x':'vader_pos',\n",
    "                                                    'vader_compound_x':'vader_compound' ,'roberta_neg_x' : 'roberta_neg', 'roberta_pos_x':'roberta_pos','roberta_neu_x':'roberta_neu'}).copy()\n",
    "df_merge_new1.head(2)                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_merge_new1.iterrows():\n",
    "    index = df_latest_sentiment[(df_latest_sentiment['listing_id'] == row['listing_id']) \n",
    "    & (df_latest_sentiment['id'] == row['id'])\n",
    "    & (df_latest_sentiment['reviewer_id'] == row['reviewer_id'])].index\n",
    "    df_latest_sentiment.loc[index[0], 'roberta_neg'] = row['roberta_neg']\n",
    "    df_latest_sentiment.loc[index[0], 'roberta_pos'] = row['roberta_pos']\n",
    "    df_latest_sentiment.loc[index[0], 'roberta_neu'] = row['roberta_neu']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>clean_comments</th>\n",
       "      <th>keyphrases</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "      <th>roberta_neg</th>\n",
       "      <th>roberta_pos</th>\n",
       "      <th>roberta_neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154364</th>\n",
       "      <td>3710914.0</td>\n",
       "      <td>115989408.0</td>\n",
       "      <td>11/27/2016</td>\n",
       "      <td>24562860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>this house is amazing. My family really love t...</td>\n",
       "      <td>thi house be amaze my family really love thi c...</td>\n",
       "      <td>[[\"thi house\", 0.583], [\"nice house\", 0.5484],...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.990759</td>\n",
       "      <td>0.007514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        listing_id           id        date  reviewer_id reviewer_name  \\\n",
       "154364   3710914.0  115989408.0  11/27/2016     24562860           NaN   \n",
       "\n",
       "                                                 comments  \\\n",
       "154364  this house is amazing. My family really love t...   \n",
       "\n",
       "                                           clean_comments  \\\n",
       "154364  thi house be amaze my family really love thi c...   \n",
       "\n",
       "                                               keyphrases  vader_neg  \\\n",
       "154364  [[\"thi house\", 0.583], [\"nice house\", 0.5484],...        0.0   \n",
       "\n",
       "        vader_neu  vader_pos  vader_compound  roberta_neg  roberta_pos  \\\n",
       "154364      0.579      0.421          0.9498     0.001727     0.990759   \n",
       "\n",
       "        roberta_neu  \n",
       "154364     0.007514  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latest_sentiment[df_latest_sentiment.isnull().T.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now finally update the file \n",
    "df_latest_sentiment.to_csv('./data_after_processing/reviews_related_data/comments_with_sentiments_imputed.csv',index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07de844f12b7ce505123c8a0011b27c4c32b306011201dd41064d4acde3c4bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
